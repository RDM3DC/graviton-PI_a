import numpy as np
import matplotlib.pyplot as plt

# --- Configuration ---
num_qubits = 3
target_string = "011"
target_idx = int(target_string, 2)
num_iterations = 25 # High number of steps to confirm stability

# ARP Hyperparameters (Tuned)
# alpha_r is not used but kept for clarity
alpha_r = 0.05    
mu_r = 0.005
gamma_G = 0.1     # Adaptation drive
mu_G = 0.01       # <--- INCREASED ELASTICITY/DECAY as suggested (0.001 -> 0.01)
G_init = 1.0      # Initial gain factor

# --- Quantum Setup Functions (Unchanged) ---
def initialize_superposition(n_qubits):
    num_states = 2**n_qubits
    return np.ones(num_states) / np.sqrt(num_states)

def apply_oracle(state, target_idx):
    new_state = state.copy()
    new_state[target_idx] *= -1 
    return new_state

def apply_adaptive_diffusion(state, G_amp):
    mean_amplitude = np.mean(state)
    standard_diffusion = 2 * mean_amplitude - state
    # G_amp controls interpolation: G_amp=1 -> Full Diffusion, G_amp=0 -> No Change
    new_state = state + G_amp * (standard_diffusion - state)
    return new_state

# --- The Simulation Run ---

state_vector = initialize_superposition(num_qubits)
G_amp = G_init 

# History tracking
history_target_prob = []
history_gain = []

print(f"--- ARP-Stabilized Quantum Logic (Target: |{target_string}>) ---")

for i in range(1, num_iterations + 1):
    
    # 1. Quantum Step A: Oracle (Phase Mark)
    state_vector = apply_oracle(state_vector, target_idx)
    
    # 2. Quantum Step B: Adaptive Diffusion (Amplitude Amplify)
    state_vector = apply_adaptive_diffusion(state_vector, G_amp)
    
    # Calculate Current State Metrics
    prob_vector = np.abs(state_vector)**2
    target_prob = prob_vector[target_idx]
    error = 1.0 - target_prob # Error: Probability Gap (1.0 is max certainty)

    # --- 3. ARP Feedback Loop (The Adaptive Pi/Gain Update) ---
    
    # The sign is FLIPPED: As ERROR decreases (Prob approaches 1.0),
    # the positive reinforcement from the error term also decreases,
    # causing the G_amp factor to be pulled down by the mu_G term.
    
    # Correction: The gain must be pulled *away* from 1.0 as the solution is found.
    # The error term should actively pull G_amp down when error is low (and G_amp is high).
    
    # A cleaner formula for this specific application:
    # G_amp resists change, but is actively driven toward zero (dampening) 
    # as the probability P gets close to 1.0.
    
    # New Update Rule: Gain is reduced by the current probability magnitude (P)
    # and resists falling below the initial state (1.0)
    G_amp += -gamma_G * target_prob + mu_G * (G_init - G_amp)
    
    # Clamping is crucial for stability
    G_amp = np.clip(G_amp, 0.0, 1.0)
    
    # Record stats
    history_target_prob.append(target_prob)
    history_gain.append(G_amp)
    
    # We will only print key iterations to avoid overwhelming the log
    if i % 5 == 0 or i == 1:
        print(f"Iter {i:2d}: Prob={target_prob:.4f} | Gain={G_amp:.4f} | Error={error:.4f}")

# 4. Visualization
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: Convergence History
ax1.plot(range(1, num_iterations+1), history_target_prob, 'o-', color='red', label='Target Probability')
ax1.set_title("ARP-Stabilized Amplitude Amplification")
ax1.set_xlabel("Iteration Step")
ax1.set_ylabel("Probability")
ax1.set_ylim(0, 1.05)
ax1.grid(True)
ax1.legend()

# Plot 2: Adaptive Gain (G_amp) History
ax2.plot(range(1, num_iterations+1), history_gain, 'o--', color='blue', label='Adaptive Gain ($G_{amp}$)')
ax2.set_title("ARP Gain Dynamics (Prevents Overshoot)")
ax2.set_xlabel("Iteration Step")
ax2.set_ylabel("Gain Factor")
ax2.set_ylim(0, 1.05)
ax2.axhline(y=G_init, color='gray', linestyle=':', label='Initial Gain (1.0)')
ax2.grid(True)
ax2.legend()

plt.tight_layout()
plt.show()
